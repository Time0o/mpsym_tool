#!/usr/bin/env python3

import operator as op
import sys

from functools import partial, reduce
from itertools import permutations, product
from os.path import dirname, join, realpath
from random import choices, sample, shuffle

sys.path.insert(1, join(dirname(realpath(__file__)), '..'))

from modules.args import NiceArgumentParser
from modules.util import error, progress, progress_done, usage


USAGE = usage(__file__, """[--min-task MIN_TASK]
                           --max-task MAX_TASK
                           --num-tasks NUM_TASKS
                           [--non-unique]
                           [--processor-sharing]
                           NUM_ALLOCATIONS""")

DESC = "Generate random task allocations"


def count_max_unique_allocations(min_tasks,
                                 max_tasks,
                                 num_tasks,
                                 processor_sharing):

    unique_tasks = max_tasks - min_tasks + 1

    if processor_sharing:
        return unique_tasks**num_tasks
    else:
        return reduce(op.mul, range(unique_tasks, unique_tasks - num_tasks, -1), 1)


def generate_all_unique_allocations(min_task,
                                    max_task,
                                    num_tasks,
                                    processor_sharing):

    domain = range(min_task, max_task + 1)

    if processor_sharing:
        task_allocations = list(product(domain, repeat=num_tasks))
    else:
        task_allocations = list(permutations(domain, r=num_tasks))

    shuffle(task_allocations)

    return task_allocations

def generate_random_allocations(min_task,
                                max_task,
                                num_tasks,
                                num_allocations,
                                unique,
                                processor_sharing):

    tasks = list(range(min_task, max_task + 1))

    task_allocations = []

    if unique:
      task_allocations_set = set()

    def sample_task_allocation():
        s = choices if processor_sharing else sample

        return tuple(s(tasks, k=num_tasks))

    for i in range(num_allocations):
        progress("generating task allocation", i, num_allocations)

        if unique:
            while True:
                task_allocation = sample_task_allocation()

                if task_allocation not in task_allocations_set:
                    task_allocations_set.add(task_allocation)
                    task_allocations.append(task_allocation)
                    break
        else:
            task_allocations.append(sample_task_allocation())

    progress_done()

    return task_allocations


if __name__ == '__main__':
    parser = NiceArgumentParser(usage=USAGE, description=DESC)

    parser.add_argument('--min-task', type=int, default=1,
        help="minimum task id")

    parser.add_argument('--max-task', required=True, type=int,
        help="maximum task id")

    parser.add_argument('--num-tasks', required=True, type=int,
        help="tasks per allocation")

    parser.add_argument('--non-unique', action='store_true',
        help="allow duplicate allocations")

    parser.add_argument('--processor-sharing', action='store_true',
        help="allow multiple tasks to be allocated to the same processor")

    parser.add_argument('num_allocations', metavar='NUM_ALLOCATIONS',
        help="number of allocations to generate")

    ns = parser.parse_args()

    if ns.min_task < 1 or ns.max_task < 1:
        error(__file__, "task ids must be > 0")

    if ns.min_task > ns.max_task:
        error(__file__, "--min-task must be <= --max-task")

    if not ns.processor_sharing and ns.max_task - ns.min_task + 1 < ns.num_tasks:
        error(__file__, "number of unique tasks smaller than tasks per allocation")

    if ns.num_tasks < 0:
        error(__file__, "--num-tasks must be > 0")

    if ns.num_allocations == 'MAX':
        if ns.non_unique:
            error(__file__, "NUM_ALLOCATIONS can only be MAX if --non-unique is not set")
    else:
        try:
            ns.num_allocations = int(ns.num_allocations)
        except:
            error(__file__, "NUM_ALLOCATIONS must be an integer or 'MAX'")

        if ns.num_allocations < 0:
            error(__file__, "NUM_ALLOCATIONS must be > 0")

    if not ns.non_unique:
        max_allocations = count_max_unique_allocations(ns.min_task,
                                                       ns.max_task,
                                                       ns.num_tasks,
                                                       ns.processor_sharing)

        if ns.num_allocations == 'MAX':
            ns.num_allocations = max_allocations
        elif ns.num_allocations > max_allocations:
            fmt = "NUM_ALLOCATIONS is too large (must be {} at most)"
            error(__file__, fmt.format(max_allocations))

    generate_all = partial(
        generate_all_unique_allocations,
        min_task=ns.min_task,
        max_task=ns.max_task,
        num_tasks=ns.num_tasks,
        processor_sharing=ns.processor_sharing)

    generate_random = partial(
        generate_random_allocations,
        min_task=ns.min_task,
        max_task=ns.max_task,
        num_tasks=ns.num_tasks,
        unique=(not ns.non_unique),
        processor_sharing=ns.processor_sharing)

    if not ns.non_unique and ns.num_allocations == max_allocations:
       task_allocations = generate_all()
    elif not ns.non_unique and ns.num_allocations > max_allocations // 2:
        task_allocations_all = generate_all()

        task_allocations_delta = generate_random(
            num_allocations=(max_allocations - ns.num_allocations))

        task_allocations = list(
            set(task_allocations_all) - set(task_allocations_delta))
    else:
        task_allocations = generate_random(num_allocations=ns.num_allocations)

    for task_allocation in task_allocations:
        print(' '.join([str(t) for t in task_allocation]))
